# ğŸ§  Reddit User Persona Generator (LLM-Powered) â€“ BeyondChats Assignment

This project generates structured user personas from Reddit profiles using a local LLM (TinyLlama). Given any Reddit username, the system scrapes their recent posts/comments and builds a human-like persona with citations using language modeling.


## ğŸš€ Features

- ğŸ” Scrapes Reddit posts and comments via PRAW
- ğŸ¤– Generates concise user personas using a local LLM (TinyLlama via Ollama)
- ğŸ“„ Outputs results as clean, structured `.txt` files
- ğŸ§¾ Citations included (e.g., Post 1 from r/AskReddit)
- âœ… Modular design â€“ Easily switch to GPT-4, Mistral, or any other model


## ğŸ› ï¸ Tech Stack

| Purpose          | Tech Used                |
|------------------|--------------------------|
| Reddit Scraping  | `praw`                   |
| Persona Modeling | `TinyLlama` via `Ollama` |
| CLI Interface    | `argparse` + `rich`      |
| Secrets Handling | `python-dotenv`          |
| Output Format    | Plaintext `.txt`         |


## ğŸ§ª Sample Usage

```bash
python src/main.py --url https://www.reddit.com/user/Hungry-Move-6603 --model ollama
```
Output is saved to: output/Hungry-Move-6603_persona.txt

ğŸ—ƒï¸ Project Structure
```bash
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                  # Entry point
â”‚   â”œâ”€â”€ persona_generator.py     # Generates persona using Ollama
â”‚   â”œâ”€â”€ reddit_scraper.py        # Fetches Reddit posts/comments
â”‚   â”œâ”€â”€ utils.py                 # Text cleaning + citation helpers
â”œâ”€â”€ output/                      # Generated personas
â”œâ”€â”€ .env.template                # Example env vars
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md
```

## Environment Variables
Copy .env.template and rename it to .env. Fill in your Reddit credentials:
```bash
Environment Variables
Copy .env.template and rename it to .env. Fill in your Reddit credentials:
```
Ollama will use the TinyLlama model automatically.

## Why TinyLlama?
â€œI chose TinyLlama to ensure fast, local persona generation on limited hardware (i5-1235U, 8GB RAM). It balances speed and quality, with modularity to swap in Mistral or GPT-4 if required.â€

This shows resource-aware engineering â€” a key skill for real-world AI deployment.

## Model Output Example
``bash
## User Persona: Hungry-Move-6603

### Interests
- Interested in startup culture and tech innovations
â†³ Source: Post 1 (r/startups)

### Communication Style
- Informal, humorous, uses emojis
â†³ Source: Comment 2 (r/funny)

### Personality Traits
- Curious, helpful, and slightly sarcastic
â†³ Source: Post 2 (r/technology)

```

âœ… How to Run
Clone this repo

Set up .env

Run:

bash
Copy
Edit

```bash
pip install -r requirements.txt
python src/main.py --url <Reddit Profile URL> --model ollama
```

## Notes
Output files are saved in output/ folder

Only recent 3 posts & 2 comments are analyzed (can be changed)

To switch to OpenAI or other models, plug into the modular interface

## ğŸ™‹ About Me
This project was submitted as part of the AI/LLM Engineer Internship Assignment for BeyondChats.
Feel free to explore, suggest, or fork!

Designed for performance, readability, and future extensibility.
